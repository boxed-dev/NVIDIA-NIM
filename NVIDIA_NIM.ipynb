{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rLayOCoer3iT",
        "outputId": "28d3330c-e77d-4dd1-b001-6223a60b9b71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_nvidia_ai_endpoints\n",
            "  Downloading langchain_nvidia_ai_endpoints-0.0.4-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from langchain_nvidia_ai_endpoints) (3.9.3)\n",
            "Collecting langchain-core<0.2.0,>=0.1.5 (from langchain_nvidia_ai_endpoints)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow<11.0.0,>=10.0.0 (from langchain_nvidia_ai_endpoints)\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (3.7.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints)\n",
            "  Downloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (8.2.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (3.6)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (1.2.0)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.5->langchain_nvidia_ai_endpoints) (2024.2.2)\n",
            "Installing collected packages: pillow, packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain_nvidia_ai_endpoints\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.33 langchain_nvidia_ai_endpoints-0.0.4 langsmith-0.1.31 orjson-3.9.15 packaging-23.2 pillow-10.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "576cc8aff0104f5ab38328338e32da31"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain_nvidia_ai_endpoints"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings, ChatNVIDIA"
      ],
      "metadata": {
        "id": "xFu6oeuKr9mH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community langchain-text-splitters faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5tsia4AsK_t",
        "outputId": "a88d8511-9ec9-4a51-8e06-9d877b20decb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.29)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.31)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (2.6.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.9.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-community) (2.16.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "loader = WebBaseLoader(\"https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers/\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "b_TCFo4dsPH2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6kPRETjSvke",
        "outputId": "494eaec8-21ee-4ecc-8411-97c6367ad8e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"\\n\\n\\n\\n\\n\\n\\n\\nNVIDIA Launches Generative AI Microservices for Developers to Create and Deploy Generative AI Copilots Across NVIDIA CUDA GPU Installed Base | NVIDIA Newsroom\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Artificial Intelligence Computing Leadership from NVIDIA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPLATFORMS\\n\\n\\n  Autonomous Machines\\n\\n\\n\\n  Cloud & Data Center\\n\\n\\n\\n  Deep Learning & Ai\\n\\n\\n\\n  Design & Pro Visualization\\n\\n\\n\\n  Healthcare\\n\\n\\n\\n  High Performance Computing\\n\\n\\n\\n  Self-Driving Cars\\n\\n\\n\\n  Gaming & Entertainment\\n\\n\\n\\n\\n\\nother links\\n\\n\\nDevelopers\\nIndustries\\nShop\\nDrivers\\nSupport\\nAbout NVIDIA\\n\\n\\nView All Products\\nGPU TECHNOLOGY CONFERENCE\\nNVIDIA Blog\\nCommunity\\nCareers\\nTECHNOLOGIES\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWatch NVIDIA CEO Jensen Huang's GTC keynote to catch all the announcements and more.\\nWatch Now\\nDismiss\\n\\n\\n\\n\\n\\n\\n\\n\\nNewsroom\\n\\n\\n\\nNVIDIA in Brief\\n\\n\\nExec Bios\\n\\n\\nNVIDIA Blog\\n\\n\\nPodcast\\n\\n\\nMedia Assets\\n\\n\\nIn the News\\n\\n\\nPress Contacts\\n\\n\\nOnline Press Kit\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNVIDIA in Brief\\n\\n\\nExec Bios\\n\\n\\nNVIDIA Blog\\n\\n\\nPodcast\\n\\n\\nMedia Assets\\n\\n\\nIn the News\\n\\n\\nPress Contacts\\n\\n\\nOnline Press Kit\\n\\n\\n\\n\\n\\nPress Release\\n    \\n  \\n\\nShare\\n\\n\\n\\n\\nTweet\\n\\n\\nTwitter\\n\\n\\n\\n\\n\\nShare\\n\\n\\nLinkedIn\\n\\n\\n\\n\\n\\nShare\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\nEmail\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nic_arrow-back-to-top\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNVIDIA Launches Generative AI Microservices for Developers to Create and Deploy Generative AI Copilots Across NVIDIA CUDA GPU Installed Base\\n\\n          March 18, 2024\\n        \\n\\n\\n\\n\\n\\n\\n\\nNew Catalog of GPU-Accelerated NVIDIA NIM Microservices and Cloud Endpoints for Pretrained AI Models Optimized to Run on Hundreds of Millions of CUDA-Enabled GPUs Across Clouds, Data Centers, Workstations and PCs\\nEnterprises Can Use Microservices to Accelerate Data Processing, LLM Customization, Inference,\\xa0Retrieval-Augmented Generation and Guardrails\\nAdopted by Broad AI Ecosystem, Including Leading Application Platform Providers Cadence, CrowdStrike, SAP, ServiceNow and More\\n\\nGTC—NVIDIA today launched dozens of enterprise-grade generative AI microservices that businesses can use to create and deploy custom applications on their own platforms while retaining full ownership and control of their intellectual property.\\nBuilt on top of the\\xa0NVIDIA CUDA®\\xa0platform, the catalog of cloud-native microservices includes\\xa0NVIDIA NIM\\xa0microservices for optimized inference on more than two dozen popular AI models from NVIDIA and its partner ecosystem. In addition, NVIDIA accelerated software development kits, libraries and tools can now be accessed as\\xa0NVIDIA CUDA-X™ microservices for retrieval-augmented generation (RAG), guardrails, data processing, HPC and more. NVIDIA also separately announced over two dozen\\xa0healthcare NIM and CUDA-X microservices.\\nThe curated selection of microservices adds a new layer to NVIDIA’s full-stack computing platform. This layer connects the AI ecosystem of model developers, platform providers and enterprises with a standardized path to run custom AI models optimized for NVIDIA’s CUDA installed base of hundreds of millions of GPUs across clouds, data centers, workstations and PCs.\\nAmong the first to access the new NVIDIA generative AI microservices available in\\xa0NVIDIA AI Enterprise 5.0\\xa0are leading application, data and cybersecurity platform providers including\\xa0Adobe,\\xa0Cadence,\\xa0CrowdStrike, Getty Images,\\xa0SAP,\\xa0ServiceNow, and Shutterstock.\\n“Established enterprise platforms are sitting on a goldmine of data that can be transformed into generative AI copilots,” said Jensen Huang, founder and CEO of NVIDIA. “Created with our partner ecosystem, these containerized AI microservices are the building blocks for enterprises in every industry to become AI companies.”\\nNIM Inference Microservices Speed Deployments From Weeks to Minutes\\r\\nNIM microservices provide pre-built containers powered by NVIDIA inference software — including Triton Inference Server™ and TensorRT™-LLM — which enable developers to reduce deployment times from weeks to minutes.\\nThey provide industry-standard APIs for domains such as language, speech and drug discovery to enable developers to quickly build AI applications using their proprietary data hosted securely in their own infrastructure. These applications can scale on demand, providing flexibility and performance for running generative AI in production on NVIDIA-accelerated computing platforms.\\nNIM microservices provide the fastest and highest-performing production AI container for deploying models from NVIDIA,\\xa0A121, Adept,\\xa0Cohere, Getty Images, and Shutterstock as well as open models from Google,\\xa0Hugging Face, Meta, Microsoft, Mistral AI and Stability AI.\\nServiceNow\\xa0today announced that it is using NIM to develop and deploy new domain-specific copilots and other generative AI applications faster and more cost effectively.\\nCustomers will be able to access NIM microservices from\\xa0Amazon SageMaker,\\xa0Google Kubernetes Engine\\xa0and\\xa0Microsoft Azure AI, and integrate with popular AI frameworks like\\xa0Deepset,\\xa0LangChain\\xa0and\\xa0LlamaIndex.\\nCUDA-X Microservices for RAG, Data Processing, Guardrails, HPC\\nCUDA-X microservices\\xa0provide end-to-end building blocks for data preparation, customization and training to speed production AI development across industries.\\nTo accelerate AI adoption, enterprises may use CUDA-X microservices including\\xa0NVIDIA Riva\\xa0for customizable speech and translation AI,\\xa0NVIDIA cuOpt™ for routing optimization, as well as\\xa0NVIDIA Earth-2\\xa0for high resolution climate and weather simulations.\\nNeMo Retriever™ microservices let developers link their AI applications to their business data — including text, images and visualizations such as bar graphs, line plots and pie charts — to generate highly accurate, contextually relevant responses. With these RAG capabilities, enterprises can offer more data to copilots, chatbots and generative AI productivity tools to elevate accuracy and insight.\\nAdditional\\xa0NVIDIA NeMo™ microservices\\xa0are coming soon for custom model development. These include NVIDIA NeMo Curator for building clean datasets for training and retrieval, NVIDIA NeMo Customizer for fine-tuning LLMs with domain-specific data, NVIDIA NeMo Evaluator for analyzing AI model performance, as well as\\xa0NVIDIA NeMo Guardrails\\xa0for LLMs.\\nEcosystem Supercharges Enterprise Platforms With Generative AI Microservices\\r\\nIn addition to leading application providers, data, infrastructure and compute platform providers across the NVIDIA ecosystem are working with NVIDIA microservices to bring generative AI to enterprises.\\nTop data platform providers including\\xa0Box, Cloudera, Cohesity,\\xa0Datastax, Dropbox and\\xa0NetApp\\xa0are working with NVIDIA microservices to help customers optimize their RAG pipelines and integrate their proprietary data into generative AI applications.\\xa0Snowflake\\xa0leverages NeMo Retriever to harness enterprise data for building AI applications.\\nEnterprises can deploy NVIDIA microservices included with NVIDIA AI Enterprise 5.0 across the infrastructure of their choice, such as leading clouds\\xa0Amazon Web Services (AWS),\\xa0Google Cloud,\\xa0Azure\\xa0and\\xa0Oracle Cloud Infrastructure.\\nNVIDIA microservices are also supported on over 400 NVIDIA-Certified Systems™, including servers and workstations from Cisco,\\xa0Dell Technologies,\\xa0Hewlett Packard Enterprise (HPE)\\xa0, HP,\\xa0Lenovo\\xa0and Supermicro. Separately today, HPE announced availability of HPE’s enterprise computing solution for generative AI, with planned integration of NIM and\\xa0NVIDIA AI Foundation models\\xa0into HPE’s AI software.\\nNVIDIA AI Enterprise microservices are coming to infrastructure software platforms including\\xa0VMware Private AI Foundation\\xa0with NVIDIA.\\xa0Red Hat\\xa0OpenShift supports NVIDIA NIM microservices to help enterprises more easily integrate generative AI capabilities into their applications with optimized capabilities for security, compliance and controls.\\xa0Canonical\\xa0is adding Charmed Kubernetes support for NVIDIA microservices through NVIDIA AI Enterprise.\\nNVIDIA’s ecosystem of hundreds of AI and MLOps partners, including Abridge, Anyscale, Dataiku,\\xa0DataRobot,\\xa0Glean, H2O.ai,\\xa0Securiti AI,\\xa0Scale AI,\\xa0OctoAI\\xa0and\\xa0Weights & Biases, are adding support for NVIDIA microservices through NVIDIA AI Enterprise.\\nApache Lucene,\\xa0Datastax, Faiss, Kinetica, Milvus, Redis, and Weaviate are among the vector search providers working with NVIDIA NeMo Retriever microservices to power responsive RAG capabilities for enterprises.\\nAvailability\\r\\nDevelopers can experiment with NVIDIA microservices at\\xa0ai.nvidia.com\\xa0at no charge. Enterprises can deploy production-grade NIM microservices with NVIDIA AI Enterprise 5.0 running on NVIDIA-Certified Systems and leading cloud platforms.\\nFor more information, watch the replay of\\xa0Huang’s GTC keynote\\xa0and visit the NVIDIA booth at GTC, held at the San Jose Convention Center through March 21.\\n\\n\\n\\n\\nAbout NVIDIA\\r\\nSince its founding in 1993,\\xa0NVIDIA\\xa0(NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling industrial digitalization across markets. NVIDIA is now a full-stack computing infrastructure company with data-center-scale offerings that are reshaping industry. More information at\\xa0https://nvidianews.nvidia.com/.\\nCertain statements in this press release including, but not limited to, statements as to: the benefits, impact, performance, features, and availability of NVIDIA’s products and technologies, including NVIDIA CUDA platform, NVIDIA NIM microservices, NVIDIA CUDA-X microservices, NVIDIA AI Enterprise 5.0, NVIDIA inference software including Triton Inference Server and TensorRT-LLM, NVIDIA Riva, NVIDIA cuOpt, NVIDIA Earth-2, NeMo Retriever, NVIDIA NeMo Curator, NVIDIA NeMo Customizer, NVIDIA NeMo Evaluator, NVIDIA NeMo Guardrails, NVIDIA AI Foundation models and NVIDIA AI Enterprise microservices; and established enterprise platforms sitting on a goldmine of data that can be transformed into generative AI copilots are forward-looking statements that are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic conditions; our reliance on third parties to manufacture, assemble, package and test our products; the impact of technological development and competition; development of new products and technologies or enhancements to our existing product and technologies; market acceptance of our products or our partners' products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of our products or technologies when integrated into systems; as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company's website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances.\\nMany of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements above are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.\\n© 2024 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo, CUDA, CUDA-X, NVIDIA NeMo, NVIDIA NeMo Retriever, NVIDIA NIM, NVIDIA Triton Inference Server, NVIDIA-Certified Systems, and TensorRT are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability and specifications are subject to change without notice.\\n\\n\\n\\n\\n\\n\\nMedia Contacts\\n\\n\\n\\n\\nAnna Kiachian\\nSenior PR Manager\\nNVIDIA Corporation\\n+1-650-224-9820\\nakiachian@nvidia.com\\n\\n\\n\\n\\n\\n\\nDownloads\\n\\n\\n\\n\\n\\n                Download Press Release\\n              \\n\\n\\n\\n                Download Attachments\\n              \\n\\n\\n\\n\\n\\n\\nMore Images\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNVIDIA NIM Microservices\\nDownload / File Link\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMore News\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            NVIDIA Digital Human Technologies Bring AI Characters to Life\\n          \\n\\n\\nMarch 18, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            NVIDIA Powers Japan’s ABCI-Q Supercomputer for Quantum Research\\n          \\n\\n\\nMarch 18, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            NVIDIA Unveils 6G Research Cloud Platform to Advance Wireless Communications With AI\\n          \\n\\n\\nMarch 18, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Oracle and NVIDIA to Deliver Sovereign AI Worldwide\\n          \\n\\n\\nMarch 18, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            Google Cloud and NVIDIA Expand Partnership to Scale AI Development\\n          \\n\\n\\nMarch 18, 2024\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nAbout NVIDIA\\r\\nSince its founding in 1993,\\xa0NVIDIA\\xa0(NASDAQ: NVDA) has been a pioneer in accelerated computing. The company’s invention of the GPU in 1999 sparked the growth of the PC gaming market, redefined computer graphics, ignited the era of modern AI and is fueling industrial digitalization across markets. NVIDIA is now a full-stack computing infrastructure company with data-center-scale offerings that are reshaping industry. More information at\\xa0https://nvidianews.nvidia.com/.\\nCertain statements in this press release including, but not limited to, statements as to: the benefits, impact, performance, features, and availability of NVIDIA’s products and technologies, including NVIDIA CUDA platform, NVIDIA NIM microservices, NVIDIA CUDA-X microservices, NVIDIA AI Enterprise 5.0, NVIDIA inference software including Triton Inference Server and TensorRT-LLM, NVIDIA Riva, NVIDIA cuOpt, NVIDIA Earth-2, NeMo Retriever, NVIDIA NeMo Curator, NVIDIA NeMo Customizer, NVIDIA NeMo Evaluator, NVIDIA NeMo Guardrails, NVIDIA AI Foundation models and NVIDIA AI Enterprise microservices; and established enterprise platforms sitting on a goldmine of data that can be transformed into generative AI copilots are forward-looking statements that are subject to risks and uncertainties that could cause results to be materially different than expectations. Important factors that could cause actual results to differ materially include: global economic conditions; our reliance on third parties to manufacture, assemble, package and test our products; the impact of technological development and competition; development of new products and technologies or enhancements to our existing product and technologies; market acceptance of our products or our partners' products; design, manufacturing or software defects; changes in consumer preferences or demands; changes in industry standards and interfaces; unexpected loss of performance of our products or technologies when integrated into systems; as well as other factors detailed from time to time in the most recent reports NVIDIA files with the Securities and Exchange Commission, or SEC, including, but not limited to, its annual report on Form 10-K and quarterly reports on Form 10-Q. Copies of reports filed with the SEC are posted on the company's website and are available from NVIDIA without charge. These forward-looking statements are not guarantees of future performance and speak only as of the date hereof, and, except as required by law, NVIDIA disclaims any obligation to update these forward-looking statements to reflect future events or circumstances.\\nMany of the products and features described herein remain in various stages and will be offered on a when-and-if-available basis. The statements above are not intended to be, and should not be interpreted as a commitment, promise, or legal obligation, and the development, release, and timing of any features or functionalities described for our products is subject to change and remains at the sole discretion of NVIDIA. NVIDIA will have no liability for failure to deliver or delay in the delivery of any of the products, features or functions set forth herein.\\n© 2024 NVIDIA Corporation. All rights reserved. NVIDIA, the NVIDIA logo, CUDA, CUDA-X, NVIDIA NeMo, NVIDIA NeMo Retriever, NVIDIA NIM, NVIDIA Triton Inference Server, NVIDIA-Certified Systems, and TensorRT are trademarks and/or registered trademarks of NVIDIA Corporation in the U.S. and other countries. Other company and product names may be trademarks of the respective companies with which they are associated. Features, pricing, availability and specifications are subject to change without notice.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMedia Contacts\\n\\n\\nGlobal contacts for media inquiries.\\nAll Contacts\\n\\n\\n\\n\\n\\n\\nStay Informed\\n\\n\\nNewsroom updates delivered to your inbox.\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCorporate Information\\n\\nAbout NVIDIA\\nCorporate Overview\\nTechnologies\\nNVIDIA Research\\nInvestors\\nSocial Responsibility\\nNVIDIA Foundation\\n\\n\\n\\nGet Involved\\n\\nForums\\nCareers\\nDeveloper Home\\nJoin the Developer Program\\nNVIDIA Partner Network\\nNVIDIA Inception\\nResources for Venture Capitalists\\nNVIDIA Inception GPU Ventures\\nTechnical Training\\nTraining for IT Professionals\\nProfessional Services for Data Science\\n\\n\\n\\nNews & Events\\n\\nNewsroom\\nNVIDIA Blog\\nNVIDIA Technical Blog\\nWebinars\\nStay Informed\\nEvents Calendar\\nNVIDIA GTC\\nNVIDIA On-Demand\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n Sign Up for NVIDIA News \\n\\n\\n\\nSubscribe\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFollow NVIDIA\\n\\nFacebook\\n\\n\\nTwitter\\n\\n\\nLinkedIn\\n\\n\\nInstagram\\n\\n\\nYouTube\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nNVIDIA\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n            USA - United States\\n          \\n\\n\\n\\n\\nPrivacy Policy\\n\\n\\nCookie Notice\\n\\n\\nManage My Privacy\\n\\n\\nLegal\\n\\n\\nAccessibility\\n\\n\\nProduct Security\\n\\n\\nContact\\n\\n\\nCopyright © 2024 NVIDIA Corporation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\", metadata={'source': 'https://nvidianews.nvidia.com/news/generative-ai-microservices-for-developers/', 'title': 'NVIDIA Launches Generative AI Microservices for Developers to Create and Deploy Generative AI Copilots Across NVIDIA CUDA GPU Installed Base | NVIDIA Newsroom', 'description': 'NVIDIA today launched dozens of enterprise-grade generative AI microservices that businesses can use to create and deploy custom applications on their own platforms while retaining full ownership and control of their intellectual property.', 'language': 'en-us'})]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['NVIDIA_API_KEY'] = userdata.get('NVIDIA_API_KEY')\n",
        "embeddings = NVIDIAEmbeddings()"
      ],
      "metadata": {
        "id": "Ov_S3zf6thvc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "documents = text_splitter.split_documents(docs)\n",
        "vector = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vector.as_retriever()"
      ],
      "metadata": {
        "id": "mUgLl3X3x9C6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "model = ChatNVIDIA(model=\"mistral_7b\")"
      ],
      "metadata": {
        "id": "rreFP6YTsjIY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "espEpjmVs4z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b84c42f7-ce5f-4ffe-9f77-737d71962720"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatNVIDIA(client=NVEModel(base_url='https://api.nvcf.nvidia.com/v2/nvcf', get_session_fn=<class 'requests.sessions.Session'>, get_asession_fn=<class 'aiohttp.client.ClientSession'>, endpoints={'infer': '{base_url}/pexec/functions/{model_id}', 'status': '{base_url}/pexec/status/{request_id}', 'models': '{base_url}/functions'}, api_key=SecretStr('**********'), is_staging=False, timeout=60, interval=0.02, last_inputs={}, last_response=None, payload_fn=<function NVEModel.<lambda> at 0x7aeb261169e0>, headers_tmpl={'call': {'Accept': 'application/json', 'Authorization': 'Bearer {api_key}', 'User-Agent': 'langchain-nvidia-ai-endpoints'}, 'stream': {'Accept': 'text/event-stream', 'content-type': 'application/json', 'Authorization': 'Bearer {api_key}', 'User-Agent': 'langchain-nvidia-ai-endpoints'}}, stagify=functools.partial(<function NVEModel._stagify at 0x7aeb261171c0>, is_staging=False)), model='mistral_7b')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyde_template = \"\"\"Even if you do not know the full answer, generate a one-paragraph hypothetical answer to the below question:\n",
        "{question}\"\"\"\n",
        "hyde_prompt = ChatPromptTemplate.from_template(hyde_template)\n",
        "hyde_query_transformer = hyde_prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "aH6zFj1MxijC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import chain\n",
        "\n",
        "@chain\n",
        "def hyde_retriever(question):\n",
        "    hypothetical_document = hyde_query_transformer.invoke({\"question\": question})\n",
        "    return retriever.invoke(hypothetical_document)"
      ],
      "metadata": {
        "id": "IlYzH-ToxqtD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "If the question doesn't match with the context of it's a greeting then answer accordingly. But don't answer about topics other than the topics in the doc\n",
        "Question: {question}\n",
        "Always answer in points\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "answer_chain = prompt | model | StrOutputParser()"
      ],
      "metadata": {
        "id": "5nT5CRn6xyB8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@chain\n",
        "def final_chain(question):\n",
        "    documents = hyde_retriever.invoke(question)\n",
        "    for s in answer_chain.stream({\"question\": question, \"context\": documents}):\n",
        "        yield s"
      ],
      "metadata": {
        "id": "rraTFqPRyD1F"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in final_chain.stream(\"Tell me about NVIDIA NIM\"):\n",
        "    print(s, end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGsQ-qcyyGkm",
        "outputId": "496af696-c1f8-4daf-d01f-47c74248f5e8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. NVIDIA NIM (NVIDIA Inference Microservices) is a set of pre-built containers powered by NVIDIA inference software.\n",
            "2. It includes Triton Inference Server™ and TensorRT™-LLM for reducing deployment times from weeks to minutes.\n",
            "3. NVIDIA NIM provides the fastest and highest-performing production AI container for deploying models from various sources like NVIDIA, Google, Hugging Face, Microsoft, and open models.\n",
            "4. NVIDIA NIM microservices can be accessed from popular platforms like Amazon SageMaker, Google Kubernetes Engine, and Microsoft Azure AI.\n",
            "5. They can be integrated with popular AI frameworks like Deepset, LangChain, and LlamaIndex.\n",
            "6. CUDA-X microservices provide end-to-end building blocks for data preparation, customization, and training to speed production AI development across industries."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RX-POzK4Ai89"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}